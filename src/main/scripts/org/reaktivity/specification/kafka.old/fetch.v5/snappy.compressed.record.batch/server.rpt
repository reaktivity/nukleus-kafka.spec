#
# Copyright 2016-2020 The Reaktivity Project
#
# The Reaktivity Project licenses this file to you under the Apache License,
# version 2.0 (the "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at:
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#

property newTimestamp ${kafka:timestamp()}

property networkAccept "nukleus://streams/kafka#0"
property networkAcceptWindow 8192

accept ${networkAccept}
  option nukleus:window ${networkAcceptWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"

# Metadata connection
accepted
connected

read 21         # Size int32
read 3s         # ApiKey int16 (Metadata)
read 5s         # ApiVersion int16
read (int:metadataRequestId)
read -1s        # ClientId string (null)
read 1          # [TopicName] array length
  read 4s "test"
read [0x00]     # allow_auto_topic_creation (boolean)

write 85        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # brokers array length
  write 1       # broker id
  write 7s "broker1"
  write 9093    # port int32
  write -1s     # rack string (null)
write 9s "cluster 1"
write 1         # controller broker id
write 1         # topic array length
  write 0s      # error code
  write 4s "test"
  write byte 0  # is_internal
  write 1       # partition array length
    write 0s    # error code
    write 0     # partition
    write 1     # leader
    write 0     # replicas array (empty)
    write -1    # isr array (null)
    write 0     # offline replicas array (empty)

read 62         # Size int32
read 32s        # ApiKey int16 (DescribeConfigs)
read 0s         # ApiVersion int16
read (int:metadataRequestId) # CorrelationId int32
read -1s        # ClientId string (null)
read 1          # [Resources] array length
read [0x02]     # resource type int8 (topic)
read 4s "test"  # topic name
read 2          # config_names count
read 14s "cleanup.policy"
read 19s "delete.retention.ms"

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # resources count
write 0s        # error code
write -1s       # error message
write [0x02]    # resource type
write 4s "test" # topic name
write 2         # config entries count
write 14s "cleanup.policy"  # config name
write 6s "delete"           # config  value
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean
write 19s "delete.retention.ms"
write 8s "86400000"
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean

# Fetch stream
accepted
read nukleus:begin.ext ${tcp:beginEx()
                            .typeId(nukleus:id("tcp"))
                            .localAddress("0.0.0.0")
                            .localPort(0)
                            .remoteHost("broker1")
                            .remotePort(9093)
                            .build()}
connected

read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 0L
read -1L
read [0..4]

read notify FETCH_REQUEST_RECEIVED

write await WRITE_FETCH_RESPONSE

write 340
${requestId}
0
1
4s "test"                               # topic name
    1                                   # partition count
        0                               # partition id
        0s                              # error code
        1L                              # high watermark
        -1L                             # last stable offset
        0L                              # log start offset
        -1                              # aborted transaction count
        280                             # record set size
            #
            # first record batch
            #
            0L                          # first offset
            68                          # length
            0                           # leader epoch
            [0x02]                      # magic
            0x4e8723aa                  # crc
            0s                          # attributes
            0                           # last offset delta
            ${newTimestamp}             # first timestamp
            ${newTimestamp}             # max timestamp
            -1L                         # producer id
            -1s                         # producer epoch
            -1                          # first sequence
            1                           # record count
                ${kafka:varint(18)}     # record length
                [0x00]                  # attributes
                ${kafka:varint(0)}      # timestamp delta
                ${kafka:varint(0)}      # offset delta
                ${kafka:varint(-1)}     # key len
                ${kafka:varint(12)}     # value len
                "Hello, world"          # value
                ${kafka:varint(0)}      # header count
            #
            # second record batch (gzip compressed)
            #
            1L                          # first offset
            108                         # length
            0                           # leader epoch
            [0x02]                      # magic
            0x4e8723aa                  # crc
            2s                          # attributes (gzip)
            0                           # last offset delta
            ${newTimestamp}             # first timestamp
            ${newTimestamp}             # max timestamp
            -1L                         # producer id
            -1s                         # producer epoch
            -1                          # first sequence
            1                           # record count
                # snappy record (22 00 00 00 01 16 "Hello, snappy" 00)
                [0x82 0x53 0x4e 0x41 0x50 0x50 0x59 0x00 0x00 0x00]
                [0x00 0x01 0x00 0x00 0x00 0x01 0x00 0x00 0x00 0x27]
                [0x28 0x0c 0x1f 0x8b 0x08 0x00 0x09 0x01 0x74 0x53]
                [0x63 0x60 0x60 0x60 0x94 0xf2 0x48 0xcd 0xc9 0xc9]
                [0xd7 0x51 0x28 0xce 0x4b 0x2c 0x28 0xa8 0x64 0x00]
                [0x00 0x69 0x3c 0xe5 0x3d 0x14 0x00 0x00 0x00]
            #
            # third record batch
            #
            2L                          # first offset
            68                          # length
            0                           # leader epoch
            [0x02]                      # magic
            0x4e8723aa                  # crc
            0s                          # attributes
            0                           # last offset delta
            ${newTimestamp}             # first timestamp
            ${newTimestamp}             # max timestamp
            -1L                         # producer id
            -1s                         # producer epoch
            -1                          # first sequence
            1                           # record count
                ${kafka:varint(18)}     # record length
                [0x00]                  # attributes
                ${kafka:varint(0)}      # timestamp delta
                ${kafka:varint(0)}      # offset delta
                ${kafka:varint(-1)}     # key len
                ${kafka:varint(12)}     # value len
                "Hello, again"          # value
                ${kafka:varint(0)}      # header count

write flush


# historical fetch connection
accepted
read nukleus:begin.ext ${tcp:beginEx()
                            .typeId(nukleus:id("tcp"))
                            .localAddress("0.0.0.0")
                            .localPort(0)
                            .remoteHost("broker1")
                            .remotePort(9093)
                            .build()}
connected
